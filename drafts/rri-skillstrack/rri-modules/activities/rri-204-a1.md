---
- type: 
  - group activity game
  - individual activity game
- duration: 45-60 minutes
- module: rri-204
---

# Selecting and Evaluating Claims

![Illustration of project team members selecting claims to explain an AI system and project]()

## Summary

This activity is designed to help you (and your group) identify, understand, and evaluate claims made about a project, data, model or system in service of providing an explanation to some stakeholder or affected user.
You will need to both identify specific types of claims, based on whether they support different objectives, such as project transparency, model interpretability or situated explanations, and also evaluate the quality of these claims, based on their ability to meet these objectives.
Then, using a case study, you will need to develop a set of claims for the hypothetical project and evaluate whether they would be positively or negatively evaluated by the relevant stakeholders.
The purpose of this task is to help you better understand the different facets of explainability and their relative strengths and weaknesses.

## Learning Objectives

- Improve ability to identify the different facets of explainability based on example claims made about a project, its data, and the respective model or system
- Gain experience with developing claims that are well suited to different explainability objectives, such as project transparency, model interpretability or situated explanations
- Recognise how specific claims may be evaluated or judged by different stakeholders or affected users, and whether they are sufficient to meet their relative needs

## Instructions

### Pre-requisites

To carry out this activity, you will need the following:

- A case study selected from our repository.
- If undertaking this activity as a group, you will need to form two (or more) breakout groups who will evaluate the claims developed by the other group(s).

### Introduction

A request for an explanation is also a request for some reason or claim made about the target of the explanation.
For instance, if you are asked why you were late for a meeting, you might respond as follows:

> I was late because my train was delayed due to a signal failure.

This is a claim made about the reason for your lateness.

Claims differ in their quality and ability to meet the expectations of the person requesting the explanation.
Again, using the example of being late for a meeting, you might respond as follows:

> I was late because I spent too much time on social media before leaving the house.

While a valid explanation in terms of its truthfulness, it is unlikely to be well received by the person requesting the explanation.

In our explainability module, you were introduced to three different facets of explainability. These facets will be used in this activity to help 

- Project Transparency
- Model Interpretability
- Situated Explanations

