---
slideOptions:
  transition: slide
  spotlight:
    enabled: true
---

# Explainability (Section 3): Model Interpretability

> **Note**
> The following sections are part of this module:
>
> - Section 1: [What is Explainability?](rri-203-1.md)
> - Section 2: [Project Transparency](rri-203-2.md)
> - Section 3: [Model Interpretability](rri-203-3.md)
> - Section 4: [Situating Explanations](rri-203-4.md)

---

Software packages for model interpretability: 

- https://github.com/interpretml/interpret#supported-techniques 
- documentation: https://interpret.ml/docs/intro.html 

Model interpretabilty is important for practical reasons such as debugging (e.g why is a model performing poorly? How can it be improved?). However, here we will focus on the ethical issues, or those that fall under the banner of responsible research and innovation.

<!-- start admonition -->
**Realtions Between Weights and Explanations**
Consider a simple linear regression model such as the following, which predicts the expected time in which a runner will finish a marathon:

$$ \hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + [...] + \beta_n x_n $$

Let's assume that the input variable $$x_1$$ refers to the number of training sessions the runner has completed in the past year. And, let's assume that the model has learned that the more training sessions a runner has completed, the faster they will finish the marathon, as evidence by a positive weight for $$\beta_1$$.

So far, so good.

[...]

What appears to be an unimportant feature at first turns out not to be the case. It is only when we learn about the relationship between the two variables that we understand the relative importance of the weights. As Christopher Molnar states:

> The interpretation of a single weight always comes with the footnote that the other input features remain at the same value, which is not the case with many real applications [...] The weights only make sense in the context of the other features in the model.[^molnar2022]

[^molnar2022]: Molnar, C. (2022). Interpretable Machine Learning. A Guide for Making Black Box Models Explainable. https://christophm.github.io/interpretable-ml-book/scope-of-interpretability.html
