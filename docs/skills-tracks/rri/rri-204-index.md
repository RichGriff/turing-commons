---
hide:
  - navigation
  - toc
---

# About this Module

<!-- This page should list learning objectives for this module and provide a summary. -->

[...]

> **Note for Index Page**
> This module is not a technical introduction to Interepretable ML methods, nor does it attempt to provide an up-to-date overview of the current methods in Interpretable ML or Explainable AI.
> New methods are currently being developed at a rapid pace, and many of these methods are designed to solve problems with specific techniques (e.g. integrated gradients and feature relevance for classificatory models).
> It is not possible, nor desirable, to keep these resources up-to-date with these sorts of developments.
> Rather, we aim to provide clarity on the practical and ethical consequences of explainability in data-driven technologies.
> As such, we discuss those methods (or classes of methods) that are well established and have wide applicability across domains and use cases.


<!-- please draft a summary of the module or copy/paste from the pre-existing HackMD file -->

## Learning Objectives

This module has the following learning objectives:

- Objective 1
- Objective 2

## Table of Contents

<div class="grid cards" markdown>

-   :octicons-beaker-16:{ .lg .middle } __What is Explainability?__

    ---

    This section...

    [:octicons-arrow-right-24: Go to module](rri-204-1.md)

-   :fontawesome-solid-arrows-spin:{ .lg .middle } __Project Transparency__

    ---

    This section...

    [:octicons-arrow-right-24: Go to module](rri-204-2.md)

-   :material-thought-bubble:{ .lg .middle } __Model Interpretability__

    ---

    This section...

    [:octicons-arrow-right-24: Go to module](rri-204-3.md)

-   :material-chat-processing:{ .lg .middle } __Situated Explanations__

    ---

    This section...

    [:octicons-arrow-right-24: Go to module](rri-204-4.md)

</div>

